{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2 as pg\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "import pandas.io.sql as psql\n",
    "import datetime as dt\n",
    "import sys\n",
    "import pymysql\n",
    "from pyxlsb import convert_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create engine for load data from pandas\n",
    "engine = create_engine('postgresql://operator:Mimoza2019@192.168.58.55:5432/anamnez_copy')\n",
    "\n",
    "#connection to use with raw sql\n",
    "connection = pg.connect(\"host='192.168.58.55' dbname=anamnez_copy user=operator password='Mimoza2019'\")\n",
    "connection.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT);\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RECORDS STAGING PART\n",
    "======================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/das/db_develop/src_copy/2021/imp7_.xlsx']\n"
     ]
    }
   ],
   "source": [
    "# Пример пути all_files = glob.glob(\"F:/anamnez/in/**/ПЗ*.csv\", recursive=True)\n",
    "#all_files = glob.glob(\"/home/das/db_develop/src_files/full/2018/*.xlsx\", recursive=True)\n",
    "all_files = sorted(glob.glob(\"/home/das/db_develop/src_copy/2021/imp7_.xlsx\", recursive=True))\n",
    "print(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_table_name=\"records_staging\"\n",
    "tmp_table_name = dst_table_name+'_tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#sql_command = \"DROP TABLE IF EXISTS %s;\"%tmp_table_name;\n",
    "#print(sql_command)\n",
    "#cursor.execute(sql_command)\n",
    "#connection.commit()\n",
    "#sql_command = \"CREATE INDEX unique_recs ON %s ((description || ' ' || gtd));\"%dst_table_name;\n",
    "#print(sql_command)\n",
    "#cursor.execute(sql_command)\n",
    "#connection.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE IF EXISTS records_staging_tmp; create table records_staging_tmp as table records_staging WITH NO DATA; alter table records_staging drop column if exists id;\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Создаем копию таблицы: структура без данных\n",
    "sql_command = \"DROP TABLE IF EXISTS \"+tmp_table_name+\"; create table \"+tmp_table_name+\" as table \"+dst_table_name+\" WITH NO DATA; alter table \"+dst_table_name+\" drop column if exists id;\"\n",
    "                    \n",
    "print(sql_command)\n",
    "cursor.execute(sql_command)\n",
    "connection.commit()\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading xlsx file: /home/das/db_develop/src_copy/2021/imp7_.xlsx\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
      "Removed 28487 duplicates\n",
      "Save file: /home/das/db_develop/src_copy/2021/imp7_.xlsx to database table records_staging_tmp\n",
      "Done.\n",
      "2021-07-01 00:25:34\n",
      "CPU times: user 4min 10s, sys: 42.8 s, total: 4min 53s\n",
      "Wall time: 8min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 1h 44min 49s (12+7 files)\n",
    "\n",
    "\n",
    "\n",
    "## In case @IndexError list index out of range@ you must open caused file,\n",
    "## copy matching data, paste only values and save in new file\n",
    "\n",
    "\n",
    "for file in all_files:\n",
    "    df_file=pd.DataFrame()\n",
    "    if (file.find('.xlsx')>0):\n",
    "        print(\"Loading xlsx file: \"+file)\n",
    "        df_file=pd.read_excel(file)\n",
    "    if (file.find('.xlsb')>0):\n",
    "        print(\"Loading xlsb file: \"+file)\n",
    "        df_file=pd.read_excel(file, engine='pyxlsb')\n",
    "        df_file['date']=df_file['date'].apply(convert_date) # convert date from xlsb format (123456.789012) to datetime\n",
    "    df=df_file\n",
    "    #df['date'] = pd.to_datetime(df['date'],format='%d-%m-%Y', errors='coerce')\n",
    "    #print(df['date'][1])\n",
    "    #df['date']=df['date'].dt.date\n",
    "    print(type(df['date'][0]))\n",
    "    df=df.round({'cost_fact': 2, 'cost_customs': 2})\n",
    "    df['gtd']=df['gtd'].apply(lambda x: x.replace(\" \",\"\"))\n",
    "    df['trademark']=df['trademark'].str.strip()\n",
    "    before_rows=df.shape[0]\n",
    "    df.drop_duplicates(subset=['description','date','gtd'],inplace=True)\n",
    "    after_rows=df.shape[0]\n",
    "    print('Removed '+str(before_rows - after_rows)+' duplicates')\n",
    "    df['hash'] = df.apply(lambda x: hash(tuple(x)), axis = 1)\n",
    "    print(\"Save file: \"+file+\" to database table \" + tmp_table_name)\n",
    "    df.to_sql(tmp_table_name, engine, if_exists='append',index=False)\n",
    "    print(\"Done.\")\n",
    "\n",
    "## uncomment if if_exists = 'replace'\n",
    "#sql_command='ALTER TABLE '+table_name+' ADD CONSTRAINT \"hash\" UNIQUE (\"hash\");'\n",
    "#print(sql_command)\n",
    "#cursor.execute(sql_command)\n",
    "#connection.commit()\n",
    "print(df['date'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alter table records_staging drop constraint if exists records_staging_pkey;\n",
      "insert into records_staging SELECT rst.sender_name,rst.recipient_code,rst.recipient_name,rst.product_code,rst.trademark,rst.description,rst.country,rst.cost_customs,rst.cost_fact,rst.date,rst.gtd,rst.hash FROM records_staging_tmp rst LEFT JOIN records_staging rs USING (DATE) WHERE rs.DATE IS NULL ;\n",
      "alter table records_staging \tadd id serial not null;create unique index records_staging_id_uindex \ton records_staging (id); alter table records_staging \tadd constraint records_staging_pk \t\tprimary key (id);\n",
      "CPU times: user 32.4 ms, sys: 1.69 ms, total: 34.1 ms\n",
      "Wall time: 7min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 4min 47s\n",
    "#if update (query works - it's checked!!!)\n",
    "# перед заливкой необходимо удалить primary_key в records_staging\n",
    "# 1\n",
    "sql_command = \"alter table \"+dst_table_name+\" drop constraint if exists records_staging_pkey;\"\n",
    "print(sql_command)\n",
    "cursor.execute(sql_command)\n",
    "connection.commit()\n",
    "\n",
    "# 2\n",
    "sql_command = \"insert into \"+dst_table_name+\" SELECT rst.sender_name,rst.recipient_code,rst.recipient_name,rst.product_code,rst.trademark,rst.description,rst.country,rst.cost_customs,rst.cost_fact,rst.date,rst.gtd,rst.hash FROM \"+tmp_table_name+\" rst LEFT JOIN \"+dst_table_name+\" rs USING (DATE) WHERE rs.DATE IS NULL ;\"\n",
    "#zero load\n",
    "#sql_command = \"insert into \"+dst_table_name+\" select * from \"+table_name\n",
    "\n",
    "#  ОШИБКА: нулевое значение в столбце \"id\" нарушает ограничение NOT NULL\n",
    "# но ведь id у меня PRIMARY KEY и Not Null, он же должен автоматом генериться, не?\n",
    "# Если у Вас тип integer, то нет.\n",
    "# Для инкремента нужно использовать тип SERIAL.\n",
    "print(sql_command)\n",
    "cursor.execute(sql_command)\n",
    "connection.commit()\n",
    "\n",
    "sql_command = \"alter table records_staging \\\n",
    "\tadd id serial not null;\\\n",
    "create unique index records_staging_id_uindex \\\n",
    "\ton records_staging (id); \\\n",
    "alter table records_staging \\\n",
    "\tadd constraint records_staging_pk \\\n",
    "\t\tprimary key (id);\"\n",
    "print(sql_command)\n",
    "cursor.execute(sql_command)\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELETE FROM records_staging r where exists ( select 'x' from records_staging rr where rr.description = r.description and rr.gtd = r.gtd and rr.cost_fact = r.cost_fact and r.ctid < rr.ctid );\n",
      "Done\n",
      "CPU times: user 23.7 ms, sys: 1.6 ms, total: 25.3 ms\n",
      "Wall time: 6min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# нельзя использовать поле date, т.к. разные поставщики данных могут использовать только дату или дату+время\n",
    "delete_duplicates=\"DELETE FROM records_staging r where exists ( select 'x' from records_staging rr where rr.description = r.description and rr.gtd = r.gtd and rr.cost_fact = r.cost_fact and r.ctid < rr.ctid );\"  \n",
    "##60293 rows affected in 11 m 33 s 247 ms\n",
    "\n",
    "\n",
    "print(delete_duplicates)\n",
    "cursor.execute(delete_duplicates)\n",
    "connection.commit()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truncate records_competitors RESTART IDENTITY CASCADE;create table if not exists records_competitors as table records_staging WITH NO DATA; insert into records_competitors select * from records_staging where recipient_code in (select competitor_code from competitors);\n",
      "alter table records_competitors drop constraint records_competitors_pkey;    alter table records_competitors ADD PRIMARY KEY (id);     create sequence if not exists records_competitors_id_seq;     alter table records_competitors alter column id set default nextval('public.records_competitors_id_seq');     alter sequence records_competitors_id_seq owned by records_competitors.id;\n",
      "create index records_competitors_recipient_name_index on records_competitors (recipient_name);                 create index records_competitors_description_index on records_competitors (description);                 create index records_competitors_gtd_index on records_competitors (gtd);\n"
     ]
    },
    {
     "ename": "DuplicateTable",
     "evalue": "ОШИБКА:  отношение \"records_competitors_recipient_name_index\" уже существует\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDuplicateTable\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mDuplicateTable\u001b[0m: ОШИБКА:  отношение \"records_competitors_recipient_name_index\" уже существует\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sql_command = \"truncate records_competitors RESTART IDENTITY CASCADE;\\\n",
    "create table if not exists records_competitors as table records_staging WITH NO DATA; \\\n",
    "insert into records_competitors select * from records_staging where recipient_code in (select competitor_code from competitors);\"\n",
    "print(sql_command)\n",
    "cursor.execute(sql_command)\n",
    "connection.commit()\n",
    "# создание primary key в records_comprtitiors\n",
    "sql_command = \"alter table records_competitors drop constraint records_competitors_pkey;\\\n",
    "    alter table records_competitors ADD PRIMARY KEY (id); \\\n",
    "    create sequence if not exists records_competitors_id_seq; \\\n",
    "    alter table records_competitors alter column id set default nextval('public.records_competitors_id_seq'); \\\n",
    "    alter sequence records_competitors_id_seq owned by records_competitors.id;\"; \n",
    "print(sql_command)\n",
    "cursor.execute(sql_command)\n",
    "connection.commit()\n",
    "#create index records_competitors_sender_name_index on records_competitors (sender_name); \\\n",
    "sql_command = \"create index records_competitors_recipient_name_index on records_competitors (recipient_name); \\\n",
    "                create index records_competitors_description_index on records_competitors (description); \\\n",
    "                create index records_competitors_gtd_index on records_competitors (gtd);\"\n",
    "print(sql_command)\n",
    "cursor.execute(sql_command)\n",
    "connection.commit()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alter table records_staging add id bigserial not null;    alter table records_staging ADD PRIMARY KEY (id);     create sequence records_staging_id_seq;     alter table records_staging alter column id set default nextval('public.records_staging_id_seq');     alter sequence records_staging_id_seq owned by records_staging.id;\n"
     ]
    },
    {
     "ename": "DuplicateColumn",
     "evalue": "ОШИБКА:  столбец \"id\" отношения \"records_staging\" уже существует\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDuplicateColumn\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-eecd48be897c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0malter\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;34m\"+dst_table_name+\"\u001b[0m\u001b[0m_id_seq\u001b[0m \u001b[0mowned\u001b[0m \u001b[0mby\u001b[0m \u001b[0;34m\"+dst_table_name+\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql_command\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql_command\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDuplicateColumn\u001b[0m: ОШИБКА:  столбец \"id\" отношения \"records_staging\" уже существует\n"
     ]
    }
   ],
   "source": [
    "# создание primary key в records_staging\n",
    "sql_command = \"alter table \"+dst_table_name+\" add id bigserial not null;\\\n",
    "    alter table \"+dst_table_name+\" ADD PRIMARY KEY (id); \\\n",
    "    create sequence \"+dst_table_name+\"_id_seq; \\\n",
    "    alter table \"+dst_table_name+\" alter column id set default nextval('public.\"+dst_table_name+\"_id_seq'); \\\n",
    "    alter sequence \"+dst_table_name+\"_id_seq owned by \"+dst_table_name+\".id;\"; \n",
    "print(sql_command)\n",
    "cursor.execute(sql_command)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_command = \"DROP TABLE IF EXISTS %s;\"%tmp_table_name;\n",
    "print(sql_command)\n",
    "\n",
    "## UNCOMMENT ONLY WHEN ALL DONE\n",
    "#cursor.execute(sql_command)\n",
    "#connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " NALOG STAGING PART\n",
    " ======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlEngine = create_engine('mysql+pymysql://operator:Mimoza2019@192.168.58.251/anamnez_gtd', pool_recycle=3600)\n",
    "dbConnection    = sqlEngine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reestr part\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reestr = pd.read_sql('SELECT * FROM Реестр', con=dbConnection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reestr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reestr.rename(columns={'Iдентифікатор документа':'doc_id', \n",
    "                 'Регіон (Продавець)':'seller_region', \n",
    "                 'Район (Продавець)':'seller_rayon',\n",
    "                 'Податковий номер (Продавець)':'seller_edrpou', \n",
    "                 'ІПН (Продавець)':'seller_ipn', \n",
    "                 'Найменування/ПІБ (Продавець)':'seller_name', \n",
    "                 'Стан (Продавець)':'seller_state', \n",
    "                 'Регіон (Покупець)':'buyer_region', \n",
    "                 'Район (Покупець)':'buyer_rayon', \n",
    "                 'Податковий номер (Покупець)':'buyer_edrpou', \n",
    "                 'ІПН (Покупець)':'buyer_ipn', \n",
    "                 'Найменування/ПІБ (Покупець)':'buyer_name', \n",
    "                 'Стан (Покупець)':'buyer_state', \n",
    "                 'Реєстр. номер у ЄРПН':'reestr_number', \n",
    "                 '№ ПН':'nn_number', \n",
    "                 'Дата виписки':'ordering_date', \n",
    "                 'Дата реєстрації':'registration_date',\n",
    "                 'Загальна сума коштів що підлягає сплаті':'total_pay_cost', \n",
    "                 'Сума ПДВ':'pdv_summ', \n",
    "                 'Обсяг операцій за ставкою 20%':'20_percent_count', \n",
    "                 'Обсяг операцій за ставкою 7%':'7_percent_count', \n",
    "                 'Кількість РК':'rk_count', \n",
    "                 'Сума коригування':'correction_cost', \n",
    "                 'Ціна постач.одиниці РК':'one_rk_cost', \n",
    "                 'Номенклатура товарів/послуг':'product_name', \n",
    "                 'Код УКТЗЕД':'product_code', \n",
    "                 'Одиниця виміру товару/ послуги':'unit', \n",
    "                 'Кількість (об’єм , обсяг)':'count', \n",
    "                 'Ціна постачання одиниці товару/послуги без ПДВ':'one_product_cost',}, \n",
    "        inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reestr_table_name = 'reestr_staging'\n",
    "sql_command = \"DROP TABLE IF EXISTS %s;\"%table_name;\n",
    "print(sql_command)\n",
    "cursor.execute(sql_command)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reestr_nodup=df_reestr.drop_duplicates(subset=['seller_edrpou',\n",
    "                                  'buyer_edrpou',\n",
    "                                  'ordering_date',\n",
    "                                  'product_name',\n",
    "                                  'one_product_cost',\n",
    "                                 'count']).reset_index()\n",
    "print('Deleted duplicates:')\n",
    "#print difference beetwen original dataframe and deduplicated\n",
    "#pd.concat([df_reestr,df_reestr_nodup]).drop_duplicates(keep=False)\n",
    "df_reestr_nodup=df_reestr_nodup.drop(columns=['ID','index'])\n",
    "df_reestr_nodup['hash'] = df_reestr_nodup.apply(lambda x: hash(tuple(x)), axis = 1)\n",
    "df_reestr_nodup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Save data: to database table \" + reestr_table_name)\n",
    "df_reestr_nodup.to_sql(reestr_table_name, engine, if_exists='replace',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit part\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit = pd.read_sql('SELECT * FROM `credit`', con=dbConnection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit.rename(columns={'Iдентифікатор документа':'doc_id', \n",
    "                 'Регіон (Продавець)':'seller_region', \n",
    "                 'Район (Продавець)':'seller_rayon',\n",
    "                 'Податковий номер (Продавець)':'seller_edrpou', \n",
    "                 'ІПН (Продавець)':'seller_ipn', \n",
    "                 'Найменування/ПІБ (Продавець)':'seller_name', \n",
    "                 'Стан (Продавець)':'seller_state', \n",
    "                 'Регіон (Покупець)':'buyer_region', \n",
    "                 'Район (Покупець)':'buyer_rayon', \n",
    "                 'Податковий номер (Покупець)':'buyer_edrpou', \n",
    "                 'ІПН (Покупець)':'buyer_ipn', \n",
    "                 'Найменування/ПІБ (Покупець)':'buyer_name', \n",
    "                 'Стан (Покупець)':'buyer_state', \n",
    "                 'Реєстр. номер у ЄРПН':'reestr_number', \n",
    "                 '№ ПН':'nn_number', \n",
    "                 'Дата виписки':'ordering_date', \n",
    "                 'Дата реєстрації':'registration_date',\n",
    "                 'Загальна сума коштів що підлягає сплаті':'total_pay_cost', \n",
    "                 'Сума ПДВ':'pdv_summ', \n",
    "                 'Обсяг операцій за ставкою 20%':'20_percent_count', \n",
    "                 'Обсяг операцій за ставкою 7%':'7_percent_count', \n",
    "                 'Кількість РК':'rk_count', \n",
    "                 'Сума коригування':'correction_cost', \n",
    "                 'Ціна постач.одиниці РК':'one_rk_cost', \n",
    "                 'Номенклатура товарів/послуг':'product_name', \n",
    "                 'Код УКТЗЕД':'product_code', \n",
    "                 'Одиниця виміру товару/ послуги':'unit', \n",
    "                 'Кількість (об’єм , обсяг)':'count', \n",
    "                 'Ціна постачання одиниці товару/послуги без ПДВ':'one_product_cost',}, \n",
    "        inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_table_name = 'credit_staging'\n",
    "sql_command = \"DROP TABLE IF EXISTS %s;\"%table_name;\n",
    "print(sql_command)\n",
    "cursor.execute(sql_command)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit_nodup=df_credit.drop_duplicates(subset=['seller_edrpou',\n",
    "                                  'buyer_edrpou',\n",
    "                                  'ordering_date',\n",
    "                                  'product_name',\n",
    "                                  'one_product_cost',\n",
    "                                 'count']).reset_index()\n",
    "print('Deleted duplicates:')\n",
    "#print difference beetwen original dataframe and deduplicated\n",
    "#pd.concat([df_credit,df_credit_nodup]).drop_duplicates(keep=False)\n",
    "df_credit_nodup=df_credit_nodup.drop(columns=['index'])\n",
    "df_credit_nodup['hash'] = df_credit_nodup.apply(lambda x: hash(tuple(x)), axis = 1)\n",
    "#df_credit_nodup\n",
    "print(\"Save data: to database table \" + credit_table_name)\n",
    "df_credit_nodup.to_sql(credit_table_name, engine, if_exists='replace',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
